{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from delphi_utils import GeoMapper\n",
    "\n",
    "os.chdir(\"../../delphi_utils/data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Utility Usage\n",
    "Two functions: `add_geocode` and `replace_geocode`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "fips       date  count  total    zip    weight\n0  01123 2018-01-01    2.0    4.0  35010  0.461001\n1  01123 2018-01-01    2.0    4.0  35072  0.013264\n2  01123 2018-01-01    2.0    4.0  35089  0.017661\n3  01123 2018-01-01    2.0    4.0  36078  0.113826\n4  01123 2018-01-01    2.0    4.0  36255  0.000433\n        date    zip     count     total\n0 2018-01-01  00602  0.000000  0.000000\n1 2018-01-01  00610  0.000000  0.000000\n2 2018-01-01  00676  0.000000  0.000000\n3 2018-01-01  00677  0.000000  0.000000\n4 2018-01-01  35010  0.922001  1.844002\n"
    }
   ],
   "source": [
    "fips_data = pd.DataFrame({\n",
    "        \"fips\":[1123,48253,72003,18181],\n",
    "        \"date\":[pd.Timestamp('2018-01-01')]*4,\n",
    "        \"count\": [2,1,np.nan,10021],\n",
    "        \"total\": [4,1,np.nan,100001]\n",
    "    })\n",
    "\n",
    "# Add a new column with the new code\n",
    "gmpr = GeoMapper()\n",
    "df = gmpr.add_geocode(fips_data, \"fips\", \"zip\")\n",
    "print(df.head())\n",
    "\n",
    "# Convert a column with the new code\n",
    "gmpr = GeoMapper()\n",
    "df = gmpr.replace_geocode(fips_data, \"fips\", \"zip\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "        date  hrr        count         total\n0 2018-01-01    1     1.772347      3.544694\n1 2018-01-01  183  7157.392404  71424.648014\n2 2018-01-01  184  2863.607596  28576.351986\n3 2018-01-01  382     1.000000      1.000000\n4 2018-01-01    7     0.227653      0.455306",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>hrr</th>\n      <th>count</th>\n      <th>total</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2018-01-01</td>\n      <td>1</td>\n      <td>1.772347</td>\n      <td>3.544694</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2018-01-01</td>\n      <td>183</td>\n      <td>7157.392404</td>\n      <td>71424.648014</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2018-01-01</td>\n      <td>184</td>\n      <td>2863.607596</td>\n      <td>28576.351986</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2018-01-01</td>\n      <td>382</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2018-01-01</td>\n      <td>7</td>\n      <td>0.227653</td>\n      <td>0.455306</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "gmpr = GeoMapper()\n",
    "df = gmpr.replace_geocode(fips_data, \"fips\", \"hrr\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "df = gmpr.replace_geocode(fips_data, \"fips\", \"hrr\")\n",
    "df2 = gmpr.replace_geocode(fips_data, \"fips\", \"zip\")\n",
    "df2 = gmpr.replace_geocode(df2, \"zip\", \"hrr\")\n",
    "np.allclose(df[['count', 'total']].values, df2[['count', 'total']].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Inner Workings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deriving a crosswalk\n",
    "Given two crosswalks, we create a derived crosswalk by merging on the common code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "         zip    weight state_code\n0      00601  0.994346         72\n1      00601  0.005654         72\n2      00602  1.000000         72\n3      00603  1.000000         72\n4      00606  0.948753         72\n...      ...       ...        ...\n44405  99923  1.000000         02\n44406  99925  1.000000         02\n44407  99926  1.000000         02\n44408  99927  1.000000         02\n44409  99929  1.000000         02\n\n[44410 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>zip</th>\n      <th>weight</th>\n      <th>state_code</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00601</td>\n      <td>0.994346</td>\n      <td>72</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>00601</td>\n      <td>0.005654</td>\n      <td>72</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00602</td>\n      <td>1.000000</td>\n      <td>72</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00603</td>\n      <td>1.000000</td>\n      <td>72</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00606</td>\n      <td>0.948753</td>\n      <td>72</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>44405</th>\n      <td>99923</td>\n      <td>1.000000</td>\n      <td>02</td>\n    </tr>\n    <tr>\n      <th>44406</th>\n      <td>99925</td>\n      <td>1.000000</td>\n      <td>02</td>\n    </tr>\n    <tr>\n      <th>44407</th>\n      <td>99926</td>\n      <td>1.000000</td>\n      <td>02</td>\n    </tr>\n    <tr>\n      <th>44408</th>\n      <td>99927</td>\n      <td>1.000000</td>\n      <td>02</td>\n    </tr>\n    <tr>\n      <th>44409</th>\n      <td>99929</td>\n      <td>1.000000</td>\n      <td>02</td>\n    </tr>\n  </tbody>\n</table>\n<p>44410 rows × 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "state_df = pd.read_csv(\"state_codes_table.csv\", dtype={\"state_code\": str, \"state_id\": str, \"state_name\": str})\n",
    "zip_fips_df = pd.read_csv(\"zip_fips_table.csv\", dtype={\"zip\": str, \"fips\": str})\n",
    "zip_fips_df[\"state_code\"] = zip_fips_df[\"fips\"].str[:2]\n",
    "zip_state_code_df = zip_fips_df.merge(state_df, on=\"state_code\", how=\"left\").drop(columns=[\"fips\", \"state_id\", \"state_name\"])\n",
    "assert 52 == len(zip_state_code_df.state_code.unique())\n",
    "zip_state_code_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A weighted one requires a summation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "       fips  hrr    weight\n0     01001    1  0.039105\n1     01001    7  0.960895\n2     01003  134  0.031998\n3     01003    6  0.968002\n4     01005    2  0.974360\n...     ...  ...       ...\n5178  56039  274  0.003804\n5179  56039  423  0.996196\n5180  56041  423  1.000000\n5181  56043  274  1.000000\n5182  56045  457  1.000000\n\n[5183 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fips</th>\n      <th>hrr</th>\n      <th>weight</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>01001</td>\n      <td>1</td>\n      <td>0.039105</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>01001</td>\n      <td>7</td>\n      <td>0.960895</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>01003</td>\n      <td>134</td>\n      <td>0.031998</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>01003</td>\n      <td>6</td>\n      <td>0.968002</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>01005</td>\n      <td>2</td>\n      <td>0.974360</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5178</th>\n      <td>56039</td>\n      <td>274</td>\n      <td>0.003804</td>\n    </tr>\n    <tr>\n      <th>5179</th>\n      <td>56039</td>\n      <td>423</td>\n      <td>0.996196</td>\n    </tr>\n    <tr>\n      <th>5180</th>\n      <td>56041</td>\n      <td>423</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>5181</th>\n      <td>56043</td>\n      <td>274</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>5182</th>\n      <td>56045</td>\n      <td>457</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>5183 rows × 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "FIPS_ZIP_OUT_FILENAME = \"fips_zip_table.csv\"\n",
    "ZIP_HRR_OUT_FILENAME = \"zip_hrr_table.csv\"\n",
    "OUTPUT_DIR = \"../../delphi_utils/data\"\n",
    "from os.path import join, isfile\n",
    "\n",
    "fz_df = pd.read_csv(\n",
    "    join(OUTPUT_DIR, FIPS_ZIP_OUT_FILENAME),\n",
    "    dtype={\"fips\": str, \"zip\": str, \"weight\": float},\n",
    ")\n",
    "zh_df = pd.read_csv(\n",
    "    join(OUTPUT_DIR, ZIP_HRR_OUT_FILENAME),\n",
    "    dtype={\"zip\": str, \"hrr\": str},\n",
    ")\n",
    "\n",
    "df = (fz_df.merge(zh_df, on=\"zip\", how=\"left\")\n",
    "          .drop(columns=\"zip\")\n",
    "          .groupby([\"fips\", \"hrr\"])\n",
    "          .sum()\n",
    "          .reset_index())\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding a geocode column\n",
    "Adding a new geocode column is a merge on the left using a matching geocode. Here we translate from zip to fips on some faux data. Since this a merge on the left, invalid ZIP values present in the data, but not present in the crosswalk simply get NAN entries in their columns. Sometimes a \"weights\" column is added also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "     zip       date  count  total   fips    weight\n0  45140 2018-01-01    2.0    2.0  39025  0.523570\n1  45140 2018-01-01    2.0    2.0  39061  0.288115\n2  45140 2018-01-01    2.0    2.0  39165  0.188315\n3  45147 2018-01-02    NaN   20.0  39025  0.938776\n4  45147 2018-01-02    NaN   20.0  39061  0.061224\n5  00500 2018-01-03   20.0   40.0    NaN       NaN\n6  95616 2018-01-04  100.0    NaN  06113  1.000000\n7  95618 2018-01-05   21.0   20.0  06095  0.003372\n8  95618 2018-01-05   21.0   20.0  06113  0.996628",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>zip</th>\n      <th>date</th>\n      <th>count</th>\n      <th>total</th>\n      <th>fips</th>\n      <th>weight</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>45140</td>\n      <td>2018-01-01</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>39025</td>\n      <td>0.523570</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>45140</td>\n      <td>2018-01-01</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>39061</td>\n      <td>0.288115</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>45140</td>\n      <td>2018-01-01</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>39165</td>\n      <td>0.188315</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>45147</td>\n      <td>2018-01-02</td>\n      <td>NaN</td>\n      <td>20.0</td>\n      <td>39025</td>\n      <td>0.938776</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>45147</td>\n      <td>2018-01-02</td>\n      <td>NaN</td>\n      <td>20.0</td>\n      <td>39061</td>\n      <td>0.061224</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>00500</td>\n      <td>2018-01-03</td>\n      <td>20.0</td>\n      <td>40.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>95616</td>\n      <td>2018-01-04</td>\n      <td>100.0</td>\n      <td>NaN</td>\n      <td>06113</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>95618</td>\n      <td>2018-01-05</td>\n      <td>21.0</td>\n      <td>20.0</td>\n      <td>06095</td>\n      <td>0.003372</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>95618</td>\n      <td>2018-01-05</td>\n      <td>21.0</td>\n      <td>20.0</td>\n      <td>06113</td>\n      <td>0.996628</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "zip_data = pd.DataFrame(\n",
    "        {\n",
    "            \"zip\": [\"45140\", \"45147\", \"00500\", \"95616\", \"95618\"],\n",
    "            \"date\": pd.date_range(\"2018-01-01\", periods=5),\n",
    "            \"count\": [2, np.nan, 20, 100, 21],\n",
    "            \"total\": [2, 20, 40, np.nan, 20]\n",
    "        }\n",
    "    )\n",
    "zip_fips_df = pd.read_csv(\"zip_fips_table.csv\", dtype={\"zip\": str, \"fips\": str})\n",
    "\n",
    "data_df = zip_data.merge(zip_fips_df, left_on=\"zip\", right_on=\"zip\", how=\"left\")\n",
    "data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replacing a column\n",
    "If there are no weights, we just drop the old column and we're done. If there are weights, we multiply the data by the weights and sum over the old codes. A helpful way to think of the operation is a multiplication of the data matrix (row vectors are columns of the dataframe) D by the weights matrix W, D*W. The weights matrix is row-stochastic (i.e. rows sum to 1). \n",
    "\n",
    "Note that the aggregation step (i.e. linear combination of source code values) requires a decision for how to handle NA values. We choose to zero-fill them to avoid propagating NAs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "        date   fips       count      total\n0 2018-01-01  39025    1.047140   1.047140\n1 2018-01-01  39061    0.576229   0.576229\n2 2018-01-01  39165    0.376631   0.376631\n3 2018-01-02  39025    0.000000  18.775510\n4 2018-01-02  39061    0.000000   1.224490\n5 2018-01-04  06113  100.000000   0.000000\n6 2018-01-05  06095    0.070819   0.067446\n7 2018-01-05  06113   20.929181  19.932554",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>fips</th>\n      <th>count</th>\n      <th>total</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2018-01-01</td>\n      <td>39025</td>\n      <td>1.047140</td>\n      <td>1.047140</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2018-01-01</td>\n      <td>39061</td>\n      <td>0.576229</td>\n      <td>0.576229</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2018-01-01</td>\n      <td>39165</td>\n      <td>0.376631</td>\n      <td>0.376631</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2018-01-02</td>\n      <td>39025</td>\n      <td>0.000000</td>\n      <td>18.775510</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2018-01-02</td>\n      <td>39061</td>\n      <td>0.000000</td>\n      <td>1.224490</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2018-01-04</td>\n      <td>06113</td>\n      <td>100.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2018-01-05</td>\n      <td>06095</td>\n      <td>0.070819</td>\n      <td>0.067446</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2018-01-05</td>\n      <td>06113</td>\n      <td>20.929181</td>\n      <td>19.932554</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "data_df = data_df.drop(columns=\"zip\")\n",
    "\n",
    "# Multiply and aggregate\n",
    "data_df[[\"count\", \"total\"]] = data_df[[\"count\", \"total\"]].multiply(data_df[\"weight\"], axis=0)\n",
    "data_df = (data_df.drop(\"weight\", axis=1)\n",
    "                  .groupby([\"date\", \"fips\"])\n",
    "                  .sum()\n",
    "                  .reset_index())\n",
    "data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building population weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "               pop\nfips  zip         \n72001 00601  18465\n72141 00601    105\n72003 00602  41520\n72005 00603  54689\n72093 00606   6276\n...            ...\n02198 99923     87\n      99925    819\n      99926   1460\n      99927     94\n02275 99929   2338\n\n[44410 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>pop</th>\n    </tr>\n    <tr>\n      <th>fips</th>\n      <th>zip</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>72001</th>\n      <th>00601</th>\n      <td>18465</td>\n    </tr>\n    <tr>\n      <th>72141</th>\n      <th>00601</th>\n      <td>105</td>\n    </tr>\n    <tr>\n      <th>72003</th>\n      <th>00602</th>\n      <td>41520</td>\n    </tr>\n    <tr>\n      <th>72005</th>\n      <th>00603</th>\n      <td>54689</td>\n    </tr>\n    <tr>\n      <th>72093</th>\n      <th>00606</th>\n      <td>6276</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th rowspan=\"4\" valign=\"top\">02198</th>\n      <th>99923</th>\n      <td>87</td>\n    </tr>\n    <tr>\n      <th>99925</th>\n      <td>819</td>\n    </tr>\n    <tr>\n      <th>99926</th>\n      <td>1460</td>\n    </tr>\n    <tr>\n      <th>99927</th>\n      <td>94</td>\n    </tr>\n    <tr>\n      <th>02275</th>\n      <th>99929</th>\n      <td>2338</td>\n    </tr>\n  </tbody>\n</table>\n<p>44410 rows × 1 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "FIPS_BY_ZIP_POP_URL = (\n",
    "    \"https://www2.census.gov/geo/docs/maps-data/data/rel/zcta_county_rel_10.txt?#\"\n",
    ")\n",
    "pop_df = pd.read_csv(FIPS_BY_ZIP_POP_URL)\n",
    "\n",
    "# Create the FIPS column by combining the state and county codes\n",
    "pop_df[\"fips\"] = pop_df[\"STATE\"].astype(str).str.zfill(2) + pop_df[\"COUNTY\"].astype(\n",
    "    str\n",
    ").str.zfill(3)\n",
    "\n",
    "# Create the ZIP column by adding leading zeros to the ZIP\n",
    "pop_df[\"zip\"] = pop_df[\"ZCTA5\"].astype(str).str.zfill(5)\n",
    "\n",
    "# Pare down the dataframe to just the relevant columns: zip, fips, and population\n",
    "pop_df = pop_df[[\"zip\", \"fips\", \"POPPT\"]].rename(columns={\"POPPT\": \"pop\"})\n",
    "\n",
    "pop_df.set_index(\n",
    "    [\"fips\", \"zip\"], inplace=True\n",
    ")  # can we do without this and resetting index below?\n",
    "pop_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "312462997"
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "# 2010 Census, corresponds to 308 million population figure\n",
    "pop_df[\"pop\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We have updated the FIPS to HRR tables since the last version (James' version)\n",
    "And they haven't changed by very much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.017533503793630306"
     },
     "metadata": {},
     "execution_count": 65
    }
   ],
   "source": [
    "df_new = GeoMapper().load_crosswalk(\"fips\", \"hrr\")\n",
    "df_old = pd.read_csv(\"https://raw.githubusercontent.com/cmu-delphi/covidcast-indicators/jhu_fix_0824/_delphi_utils_python/delphi_utils/data/fips_hrr_cross.csv?token=AANZ76Q7CUS7REWHRIGNKV27KHH6U\", dtype={\"fips\": str, \"hrr\": str, \"weight\": float})\n",
    "df_old[\"fips\"] = df_old[\"fips\"].str.zfill(5)\n",
    "df = df_new.groupby([\"hrr\", \"fips\"]).sum().reset_index().merge(df_old, on=[\"fips\", \"hrr\"], how=\"left\")\n",
    "df.weight_x.sub(df.weight_y).abs().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We have updated the source for the FIPS to ZIP mapping\n",
    "Our new one comes from the US Census and the other from [simplemaps.com](https://simplemaps.com/data/us-zips)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "326256148\n"
    }
   ],
   "source": [
    "df_census = GeoMapper().load_crosswalk(\"zip\", \"fips\")\n",
    "df_simplemaps = pd.read_csv(\"../../data_proc/geomap/uszips.csv\")\n",
    "print(df_simplemaps[\"population\"].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_simplemaps[\"county_weights\"] = df_simplemaps[\"county_weights\"].transform(lambda x: list(eval(x).items()))\n",
    "df_simplemaps = df_simplemaps.explode(\"county_weights\")\n",
    "df_simplemaps[\"county_fips\"] = df_simplemaps[\"county_weights\"].apply(lambda x: x[0])\n",
    "df_simplemaps[\"county_weights\"] = df_simplemaps[\"county_weights\"].apply(lambda x: x[1]/100)\n",
    "df_simplemaps = df_simplemaps.rename(columns={\"county_fips\": \"fips\"})\n",
    "df_simplemaps[\"zip\"] = df_simplemaps[\"zip\"].astype(str).str.zfill(5)\n",
    "df_simplemaps[\"fips\"] = df_simplemaps[\"fips\"].astype(str).str.zfill(5)\n",
    "df = df_census.merge(df_simplemaps, on=[\"zip\", \"fips\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "1.1494991956541422e-05"
     },
     "metadata": {},
     "execution_count": 62
    }
   ],
   "source": [
    "df[\"weight\"].sub(df[\"county_weights\"]).abs().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "1.307895680646709e-09"
     },
     "metadata": {},
     "execution_count": 68
    }
   ],
   "source": [
    "1 - df[\"weight\"].corr(df[\"county_weights\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "113.4559999704361 147.0\n"
    }
   ],
   "source": [
    "df = df.dropna(subset=[\"population\"])\n",
    "print(df.groupby(\"zip\")[\"population\"].unique().sum()[0] - df[\"population\"].multiply(df[\"county_weights\"]).sum(),\n",
    "      df.groupby(\"zip\")[\"population\"].unique().sum()[0] - df[\"population\"].multiply(df[\"weight\"]).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JHU Time Series Data\n",
    "This is the data that our JHU indicator pulls to ingest into the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv\")\n",
    "important_columns = df[df[\"UID\"] == 84001001].filter(regex=\"\\d{0,2}/\\d{0,2}/20\").columns.to_list() + [\"UID\"]\n",
    "df = df[important_columns]\n",
    "date_columns = set(df.columns) - set([\"UID\"])\n",
    "df = df.melt(id_vars=['UID'], value_vars=date_columns).rename(columns={\"variable\": \"date\"})\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fips = GeoMapper().replace_geocode(df, \"jhu_uid\", \"fips\", \"UID\")\n",
    "df_msa = GeoMapper().add_geocode(df_fips, \"fips\", \"msa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "56210       1\n60368       1\n60987       1\n62036       1\n73827       1\n           ..\n6773350     1\n7176780     1\n9525478     1\n13262011    1\n19299786    1\nName: pop, Length: 392, dtype: int64"
     },
     "metadata": {},
     "execution_count": 185
    }
   ],
   "source": [
    "df_fipspop = GeoMapper().load_crosswalk(\"fips\", \"pop\")\n",
    "df_fipsmsa = GeoMapper().load_crosswalk(\"fips\", \"msa\")\n",
    "df = df_fipspop.merge(df_fipsmsa, on=\"fips\", how=\"left\")\n",
    "df.groupby(\"msa\")[\"pop\"].sum().value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JHU UID and FIPS Codes\n",
    "There are a number by-hand modification we have to make to the JHU UID -> FIPS map (see [here](https://cmu-delphi.github.io/delphi-epidata/api/covidcast-signals/jhu-csse.html#geographical-exceptions)). \n",
    "\n",
    "To get started, let's compare their population data to population data we use for FIPS codes. We obtain a 5.6% difference, that's not bad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.05688630188845362"
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "JHU_FIPS_URL = \"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/UID_ISO_FIPS_LookUp_Table.csv\"\n",
    "df = pd.read_csv(JHU_FIPS_URL)\n",
    "df2 = pd.read_csv(\"fips_pop.csv\")\n",
    "merged = df2.merge(df, left_on=\"fips\", right_on=\"FIPS\", how=\"left\")\n",
    "((merged[\"pop\"] - merged[\"Population\"]).abs()/merged[\"Population\"]).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we verify the hand-additions. \n",
    "\n",
    "Even though there are multiple JHU UIDs for some FIPS because of the splitting, the extra data is fine because it will likely generate NAs (for example, the Dukes and Nantucket counties are reported together, which is why they have a separate UID; we population weight split this in the two respective FIPS codes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "      jhu_uid   fips    weight\n750        16  00060  1.000000\n751       316  00066  1.000000\n752       580  00069  1.000000\n753       850  00078  1.000000\n754       630  00072  1.000000\n..        ...    ...       ...\n7    84036061  36005  0.170114\n8    84036061  36047  0.307060\n9    84036061  36061  0.195363\n10   84036061  36081  0.270350\n11   84036061  36085  0.057113\n\n[3383 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>jhu_uid</th>\n      <th>fips</th>\n      <th>weight</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>750</th>\n      <td>16</td>\n      <td>00060</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>751</th>\n      <td>316</td>\n      <td>00066</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>752</th>\n      <td>580</td>\n      <td>00069</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>753</th>\n      <td>850</td>\n      <td>00078</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>754</th>\n      <td>630</td>\n      <td>00072</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>84036061</td>\n      <td>36005</td>\n      <td>0.170114</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>84036061</td>\n      <td>36047</td>\n      <td>0.307060</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>84036061</td>\n      <td>36061</td>\n      <td>0.195363</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>84036061</td>\n      <td>36081</td>\n      <td>0.270350</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>84036061</td>\n      <td>36085</td>\n      <td>0.057113</td>\n    </tr>\n  </tbody>\n</table>\n<p>3383 rows × 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "hand_additions = pd.DataFrame(\n",
    "    [\n",
    "        # Split aggregation of Dukes and Nantucket, Massachusetts\n",
    "        {\"jhu_uid\": 84070002, \"fips\": \"25007\", \"weight\": 16/26}, # Population: 16535\n",
    "        {\"jhu_uid\": 84070002, \"fips\": \"25019\", \"weight\": 10/26}, # 10172\n",
    "        # Kansas City, Missouri\n",
    "        {\"jhu_uid\": 84070003, \"fips\": \"29095\", \"weight\": 674158 / 1084897}, # Population: 674158 \n",
    "        {\"jhu_uid\": 84070003, \"fips\": \"29165\", \"weight\": 89322 / 1084897}, # 89322\n",
    "        {\"jhu_uid\": 84070003, \"fips\": \"29037\", \"weight\": 99478 / 1084897}, # 99478\n",
    "        {\"jhu_uid\": 84070003, \"fips\": \"29047\", \"weight\": 221939 / 1084897}, # 221939\n",
    "        # Kusilvak, Alaska\n",
    "        {\"jhu_uid\": 84002158, \"fips\": \"02270\", \"weight\": 1.0},\n",
    "        # Split aggregation of New York County (populations given at JHU documentation)\n",
    "        {\"jhu_uid\": 84036061, \"fips\": \"36005\", \"weight\": 1418207/8336817}, # Population: 1,418,207\n",
    "        {\"jhu_uid\": 84036061, \"fips\": \"36047\", \"weight\": 2559903/8336817}, # 2,559,903\n",
    "        {\"jhu_uid\": 84036061, \"fips\": \"36061\", \"weight\": 1628706/8336817}, # 1,628,706\n",
    "        {\"jhu_uid\": 84036061, \"fips\": \"36081\", \"weight\": 2253858/8336817}, # 2,253,858\n",
    "        {\"jhu_uid\": 84036061, \"fips\": \"36085\", \"weight\": 476143/8336817}, # 476,143\n",
    "    ]\n",
    ")\n",
    "\n",
    "jhu_df = pd.read_csv(JHU_FIPS_URL, dtype={\"UID\": str, \"FIPS\": str})\n",
    "jhu_df = jhu_df.query(\"Country_Region == 'US'\")\n",
    "jhu_df = (\n",
    "    jhu_df[[\"UID\", \"FIPS\"]]\n",
    "    .rename(columns={\"UID\": \"jhu_uid\", \"FIPS\": \"fips\"})\n",
    "    .dropna(subset=[\"fips\"])\n",
    ")\n",
    "\n",
    "# FIPS Codes that are just two long should be zero filled.\n",
    "# These are Guam (66), Northern Mariana Islands (69), Virgin Islands (78),\n",
    "# and Puerto Rico (72).\n",
    "fips_st = jhu_df[\"fips\"].str.len() <= 2\n",
    "jhu_df.loc[fips_st, \"fips\"] = jhu_df.loc[fips_st, \"fips\"].astype(str).str.zfill(5)\n",
    "\n",
    "# Drop the JHU UIDs that were hand-modified\n",
    "dup_ind = jhu_df[\"jhu_uid\"].isin(hand_additions[\"jhu_uid\"].values)\n",
    "jhu_df.drop(jhu_df.index[dup_ind], inplace=True)\n",
    "\n",
    "# Drop the FIPS codes in JHU that were hand-modified\n",
    "dup_ind = jhu_df[\"fips\"].isin(hand_additions[\"fips\"].values)\n",
    "jhu_df.drop(jhu_df.index[dup_ind], inplace=True)\n",
    "\n",
    "# Add weights of 1.0 to everything not in hand additions, then merge in hand-additions\n",
    "# Finally, zero fill FIPS\n",
    "jhu_df[\"weight\"] = 1.0\n",
    "jhu_df = pd.concat((jhu_df, hand_additions))\n",
    "jhu_df[\"fips\"] = jhu_df[\"fips\"].astype(int).astype(str).str.zfill(5)\n",
    "jhu_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should have no FIPS codes with multiple entries, because this would imply multiple JHU UIDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[]"
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "new_df = jhu_df.groupby(\"fips\").count().reset_index()\n",
    "new_df[new_df[\"jhu_uid\"] >= 2][\"fips\"].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verifying JHU reporting\n",
    "Puerto Rico reports cases at the municipality level, while deaths are reported at the commonwealth level in the Unassigned UID (see [here](https://github.com/CSSEGISandData/COVID-19/issues/2889))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Average deaths June 1st to August 1st:  162.74193548387098\nAverage confirmed cases June 1st to August 1st:  107.18114143920596\n"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def convert_time(t):\n",
    "    \"\"\"Shape date into m/d/yy format.\"\"\"\n",
    "    return str(int(t.strftime(\"%m\"))) + \"/\" + str(int(t.strftime(\"%d\"))) +  \"/\" + t.strftime(\"%y\")\n",
    "\n",
    "# Load JHU deaths\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_US.csv\")\n",
    "\n",
    "# Get last two months\n",
    "date_cols = [convert_time(t) for t in pd.date_range(\"06-01-2020\", \"08-01-2020\")]\n",
    "puerto_rico_uids = [63072999]\n",
    "\n",
    "# Check for non-zero deaths\n",
    "print(\"Average deaths June 1st to August 1st: \", df[df[\"UID\"].isin(puerto_rico_uids)][date_cols].to_numpy().mean())\n",
    "\n",
    "# Load JHU confirmed\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv\")\n",
    "\n",
    "# Get last two months\n",
    "date_cols = [convert_time(t) for t in pd.date_range(\"06-01-2020\", \"08-01-2020\")]\n",
    "puerto_rico_uids = [int(\"630\" + str(i)) for i in range(72001, 72200)]\n",
    "\n",
    "# Check for non-zero cases\n",
    "print(\"Average confirmed cases June 1st to August 1st: \", df[df[\"UID\"].isin(puerto_rico_uids)][date_cols].to_numpy().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Any confirmed cases June 1st to August 1st?  True\nAverage confirmed cases June 1st to August 1st:  323.0806451612903\n"
    }
   ],
   "source": [
    "# Load JHU confirmed\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv\")\n",
    "\n",
    "# Get last two months\n",
    "date_cols = [convert_time(t) for t in pd.date_range(\"06-01-2020\", \"08-01-2020\")]\n",
    "puerto_rico_uids = [63072999]\n",
    "\n",
    "# Check for non-zero cases\n",
    "print(\"Any confirmed cases June 1st to August 1st? \",np.any(df[df[\"UID\"].isin(puerto_rico_uids)][date_cols].to_numpy()>0))\n",
    "print(\"Average confirmed cases June 1st to August 1st: \", df[df[\"UID\"].isin(puerto_rico_uids)][date_cols].to_numpy().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "6/1/20      3749\n6/2/20      3802\n6/3/20      3888\n6/4/20      4364\n6/5/20      4481\n           ...  \n7/28/20    14871\n7/29/20    15075\n7/30/20    15582\n7/31/20    15811\n8/1/20     16802\nLength: 62, dtype: int64"
     },
     "metadata": {},
     "execution_count": 129
    }
   ],
   "source": [
    "puerto_rico_uids = [int(\"630\" + str(i)) for i in range(72001, 72200)]\n",
    "df[df[\"UID\"].isin(puerto_rico_uids)][date_cols].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try New York. The only county that should report anything is \"36061\", which aggregates all the NY City counties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "       FIPS  Deaths\n2527  36061   23658",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>FIPS</th>\n      <th>Deaths</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2527</th>\n      <td>36061</td>\n      <td>23658</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "df_ny = df[df[\"FIPS\"].isin([\"36005\", \"36047\", \"36061\", \"36081\", \"36085\"])]\n",
    "df_ny"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about Dukes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"FIPS\"].isin([\"36005\", \"36047\", \"36061\", \"36081\", \"36085\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at Utah. It's not reported at the FIPS level, but instead is repoted in an aggregate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "           UID iso2 iso3  code3     FIPS  Admin2 Province_State  \\\n2955  84049001   US  USA    840  49001.0  Beaver           Utah   \n\n     Country_Region        Lat       Long_  ... 8/14/20  8/15/20  8/16/20  \\\n2955             US  38.356571 -113.234223  ...       0        0        0   \n\n      8/17/20  8/18/20  8/19/20  8/20/20  8/21/20  8/22/20  8/23/20  \n2955        0        0        0        0        0        0        0  \n\n[1 rows x 226 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>UID</th>\n      <th>iso2</th>\n      <th>iso3</th>\n      <th>code3</th>\n      <th>FIPS</th>\n      <th>Admin2</th>\n      <th>Province_State</th>\n      <th>Country_Region</th>\n      <th>Lat</th>\n      <th>Long_</th>\n      <th>...</th>\n      <th>8/14/20</th>\n      <th>8/15/20</th>\n      <th>8/16/20</th>\n      <th>8/17/20</th>\n      <th>8/18/20</th>\n      <th>8/19/20</th>\n      <th>8/20/20</th>\n      <th>8/21/20</th>\n      <th>8/22/20</th>\n      <th>8/23/20</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2955</th>\n      <td>84049001</td>\n      <td>US</td>\n      <td>USA</td>\n      <td>840</td>\n      <td>49001.0</td>\n      <td>Beaver</td>\n      <td>Utah</td>\n      <td>US</td>\n      <td>38.356571</td>\n      <td>-113.234223</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1 rows × 226 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 133
    }
   ],
   "source": [
    "df[df[\"UID\"].isin([84049001])] # Beaver county, no data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "           UID iso2 iso3  code3  FIPS      Admin2 Province_State  \\\n2954  84070015   US  USA    840   NaN  Bear River           Utah   \n\n     Country_Region        Lat       Long_  ... 8/14/20  8/15/20  8/16/20  \\\n2954             US  41.521068 -113.083282  ...    2372     2384     2393   \n\n      8/17/20  8/18/20  8/19/20  8/20/20  8/21/20  8/22/20  8/23/20  \n2954     2398     2405     2413     2427     2443     2464     2482  \n\n[1 rows x 226 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>UID</th>\n      <th>iso2</th>\n      <th>iso3</th>\n      <th>code3</th>\n      <th>FIPS</th>\n      <th>Admin2</th>\n      <th>Province_State</th>\n      <th>Country_Region</th>\n      <th>Lat</th>\n      <th>Long_</th>\n      <th>...</th>\n      <th>8/14/20</th>\n      <th>8/15/20</th>\n      <th>8/16/20</th>\n      <th>8/17/20</th>\n      <th>8/18/20</th>\n      <th>8/19/20</th>\n      <th>8/20/20</th>\n      <th>8/21/20</th>\n      <th>8/22/20</th>\n      <th>8/23/20</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2954</th>\n      <td>84070015</td>\n      <td>US</td>\n      <td>USA</td>\n      <td>840</td>\n      <td>NaN</td>\n      <td>Bear River</td>\n      <td>Utah</td>\n      <td>US</td>\n      <td>41.521068</td>\n      <td>-113.083282</td>\n      <td>...</td>\n      <td>2372</td>\n      <td>2384</td>\n      <td>2393</td>\n      <td>2398</td>\n      <td>2405</td>\n      <td>2413</td>\n      <td>2427</td>\n      <td>2443</td>\n      <td>2464</td>\n      <td>2482</td>\n    </tr>\n  </tbody>\n</table>\n<p>1 rows × 226 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 134
    }
   ],
   "source": [
    "df[df[\"UID\"].isin([84070015])] # Bear River aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "           UID iso2 iso3  code3  FIPS      Admin2 Province_State  \\\n2954  84070015   US  USA    840   NaN  Bear River           Utah   \n\n     Country_Region        Lat       Long_  ... 8/14/20  8/15/20  8/16/20  \\\n2954             US  41.521068 -113.083282  ...    2372     2384     2393   \n\n      8/17/20  8/18/20  8/19/20  8/20/20  8/21/20  8/22/20  8/23/20  \n2954     2398     2405     2413     2427     2443     2464     2482  \n\n[1 rows x 226 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>UID</th>\n      <th>iso2</th>\n      <th>iso3</th>\n      <th>code3</th>\n      <th>FIPS</th>\n      <th>Admin2</th>\n      <th>Province_State</th>\n      <th>Country_Region</th>\n      <th>Lat</th>\n      <th>Long_</th>\n      <th>...</th>\n      <th>8/14/20</th>\n      <th>8/15/20</th>\n      <th>8/16/20</th>\n      <th>8/17/20</th>\n      <th>8/18/20</th>\n      <th>8/19/20</th>\n      <th>8/20/20</th>\n      <th>8/21/20</th>\n      <th>8/22/20</th>\n      <th>8/23/20</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2954</th>\n      <td>84070015</td>\n      <td>US</td>\n      <td>USA</td>\n      <td>840</td>\n      <td>NaN</td>\n      <td>Bear River</td>\n      <td>Utah</td>\n      <td>US</td>\n      <td>41.521068</td>\n      <td>-113.083282</td>\n      <td>...</td>\n      <td>2372</td>\n      <td>2384</td>\n      <td>2393</td>\n      <td>2398</td>\n      <td>2405</td>\n      <td>2413</td>\n      <td>2427</td>\n      <td>2443</td>\n      <td>2464</td>\n      <td>2482</td>\n    </tr>\n  </tbody>\n</table>\n<p>1 rows × 226 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 131
    }
   ],
   "source": [
    "df_ut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('delphi': venv)",
   "language": "python",
   "name": "python_defaultSpec_1599076307768"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}